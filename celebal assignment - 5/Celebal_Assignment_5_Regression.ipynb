{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.515915Z",
          "iopub.status.busy": "2025-07-06T08:55:35.51559Z",
          "iopub.status.idle": "2025-07-06T08:55:35.523987Z",
          "shell.execute_reply": "2025-07-06T08:55:35.522647Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.515891Z"
        },
        "id": "lhf-B59fpNOZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.528405Z",
          "iopub.status.busy": "2025-07-06T08:55:35.52808Z",
          "iopub.status.idle": "2025-07-06T08:55:35.59618Z",
          "shell.execute_reply": "2025-07-06T08:55:35.595143Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.528383Z"
        },
        "id": "5jLQlRRApNOd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/data_description.txt\")\n",
        "test_df = pd.read_csv(\"/content/data_description.txt\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.598371Z",
          "iopub.status.busy": "2025-07-06T08:55:35.598057Z",
          "iopub.status.idle": "2025-07-06T08:55:35.678646Z",
          "shell.execute_reply": "2025-07-06T08:55:35.677648Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.598346Z"
        },
        "id": "zZEkO1BvpNOg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.679729Z",
          "iopub.status.busy": "2025-07-06T08:55:35.679447Z",
          "iopub.status.idle": "2025-07-06T08:55:35.698799Z",
          "shell.execute_reply": "2025-07-06T08:55:35.697798Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.679708Z"
        },
        "id": "0fiEfIDJpNOh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTp9Lgq2pNOj"
      },
      "source": [
        "##  Exploratory Data Analysis (EDA)\n",
        "We'll begin by checking the distribution of the target variable and identifying missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.701144Z",
          "iopub.status.busy": "2025-07-06T08:55:35.700842Z",
          "iopub.status.idle": "2025-07-06T08:55:35.716843Z",
          "shell.execute_reply": "2025-07-06T08:55:35.715688Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.701121Z"
        },
        "id": "CQmOgNPppNOm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:35.718044Z",
          "iopub.status.busy": "2025-07-06T08:55:35.717791Z",
          "iopub.status.idle": "2025-07-06T08:55:36.13523Z",
          "shell.execute_reply": "2025-07-06T08:55:36.134313Z",
          "shell.execute_reply.started": "2025-07-06T08:55:35.718023Z"
        },
        "id": "KbnYHcg9pNOo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Distribution of the target variable\n",
        "sns.histplot(train_df['SalePrice'], kde=True)\n",
        "plt.title(\"SalePrice Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# Log-transform if needed\n",
        "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])\n",
        "\n",
        "# Check missing values\n",
        "missing = train_df.isnull().sum()\n",
        "missing = missing[missing > 0].sort_values(ascending=False)\n",
        "missing.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:36.136966Z",
          "iopub.status.busy": "2025-07-06T08:55:36.136538Z",
          "iopub.status.idle": "2025-07-06T08:55:36.662048Z",
          "shell.execute_reply": "2025-07-06T08:55:36.660902Z",
          "shell.execute_reply.started": "2025-07-06T08:55:36.136935Z"
        },
        "id": "5bjL8ReZpNOr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Log transform the target variable\n",
        "log_saleprice = np.log1p(train_df['SalePrice'])\n",
        "\n",
        "# Plot\n",
        "sns.displot(log_saleprice, kde=True)\n",
        "plt.title(\"Log-Transformed SalePrice Distribution\")\n",
        "plt.xlabel(\"Log(SalePrice)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:36.663551Z",
          "iopub.status.busy": "2025-07-06T08:55:36.663166Z",
          "iopub.status.idle": "2025-07-06T08:55:37.018667Z",
          "shell.execute_reply": "2025-07-06T08:55:37.017527Z",
          "shell.execute_reply.started": "2025-07-06T08:55:36.663528Z"
        },
        "id": "rjCTUidApNOs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\n",
        "sns.histplot(train_df['SalePrice'],kde=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:37.02018Z",
          "iopub.status.busy": "2025-07-06T08:55:37.01988Z",
          "iopub.status.idle": "2025-07-06T08:55:37.3161Z",
          "shell.execute_reply": "2025-07-06T08:55:37.314887Z",
          "shell.execute_reply.started": "2025-07-06T08:55:37.020159Z"
        },
        "id": "n83EOQ2npNOu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import probplot\n",
        "\n",
        "# Assuming train_df is already loaded and contains 'SalePrice'\n",
        "# QQ Plot\n",
        "probplot(train_df['SalePrice'], plot=plt)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:37.319468Z",
          "iopub.status.busy": "2025-07-06T08:55:37.319175Z",
          "iopub.status.idle": "2025-07-06T08:55:41.000909Z",
          "shell.execute_reply": "2025-07-06T08:55:40.999665Z",
          "shell.execute_reply.started": "2025-07-06T08:55:37.319445Z"
        },
        "id": "l9X_rBHopNOw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Select only numerical columns from the training data\n",
        "df_num = train_df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr = df_num.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr, vmax=1.0, square=True, cmap='coolwarm', annot=True)\n",
        "plt.title(\"Correlation Matrix of Numerical Features\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:41.002121Z",
          "iopub.status.busy": "2025-07-06T08:55:41.001852Z",
          "iopub.status.idle": "2025-07-06T08:55:50.189442Z",
          "shell.execute_reply": "2025-07-06T08:55:50.188363Z",
          "shell.execute_reply.started": "2025-07-06T08:55:41.002102Z"
        },
        "id": "JzQ9nS2DpNOx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urt2cPMFpNOy"
      },
      "source": [
        "### Handling Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:50.190797Z",
          "iopub.status.busy": "2025-07-06T08:55:50.190474Z",
          "iopub.status.idle": "2025-07-06T08:55:50.20264Z",
          "shell.execute_reply": "2025-07-06T08:55:50.201625Z",
          "shell.execute_reply.started": "2025-07-06T08:55:50.190773Z"
        },
        "id": "RvBR8q0MpNOz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Combine train and test data for preprocessing\n",
        "train_labels = train_df['SalePrice']\n",
        "train_df = train_df.drop(['SalePrice'], axis=1)\n",
        "\n",
        "# Concatenate train and test\n",
        "all_data = pd.concat([train_df, test_df], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:50.204227Z",
          "iopub.status.busy": "2025-07-06T08:55:50.203943Z",
          "iopub.status.idle": "2025-07-06T08:55:50.245903Z",
          "shell.execute_reply": "2025-07-06T08:55:50.244826Z",
          "shell.execute_reply.started": "2025-07-06T08:55:50.204208Z"
        },
        "id": "FzWRXgjfpNO0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "null_columns = all_data.columns[all_data.isna().any()]\n",
        "columns_with_null =all_data[null_columns]\n",
        "nullcounts = columns_with_null.isna().sum().sort_values(ascending=False)\n",
        "\n",
        "# usually we ignore the columns when percentage of null values exceeds than 25%\n",
        "null_percent = (nullcounts/len(all_data)) * 100\n",
        "null_percent_df = pd.DataFrame({\"Total\":nullcounts,\"Missing Ratio\":null_percent})\n",
        "null_percent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:50.247284Z",
          "iopub.status.busy": "2025-07-06T08:55:50.246829Z",
          "iopub.status.idle": "2025-07-06T08:55:51.127744Z",
          "shell.execute_reply": "2025-07-06T08:55:51.126407Z",
          "shell.execute_reply.started": "2025-07-06T08:55:50.247195Z"
        },
        "id": "0kjGx92LpNO1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#visualizing the missing value by percentage\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.xticks(rotation=90)\n",
        "sns.barplot(y=null_percent,x =null_percent.index )\n",
        "plt.xlabel('Missing values ',fontsize=15)\n",
        "plt.ylabel('Percent of Missing value',fontsize=15)\n",
        "plt.title('Percentage of Missing value for each Features',fontsize = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.129261Z",
          "iopub.status.busy": "2025-07-06T08:55:51.12887Z",
          "iopub.status.idle": "2025-07-06T08:55:51.172499Z",
          "shell.execute_reply": "2025-07-06T08:55:51.171318Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.129239Z"
        },
        "id": "YmWwIFxMpNO2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Handle categorical columns\n",
        "categorical_cols = all_data.select_dtypes(include='object').columns\n",
        "all_data[categorical_cols] = all_data[categorical_cols].fillna(\"NA\")\n",
        "\n",
        "# Handle numerical columns\n",
        "numerical_cols = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
        "for col in numerical_cols:\n",
        "    if all_data[col].isna().sum() > 0:\n",
        "        all_data[col] = all_data[col].fillna(all_data[col].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQWpM2fKpNO3"
      },
      "source": [
        "### Model Training and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.173928Z",
          "iopub.status.busy": "2025-07-06T08:55:51.173644Z",
          "iopub.status.idle": "2025-07-06T08:55:51.212705Z",
          "shell.execute_reply": "2025-07-06T08:55:51.211628Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.173901Z"
        },
        "id": "q7kEfCVxpNO3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.214145Z",
          "iopub.status.busy": "2025-07-06T08:55:51.213814Z",
          "iopub.status.idle": "2025-07-06T08:55:51.220529Z",
          "shell.execute_reply": "2025-07-06T08:55:51.219043Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.214121Z"
        },
        "id": "EUFrG_fMpNO3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(train_df.columns)  # See if 'SalePrice' is there\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.22197Z",
          "iopub.status.busy": "2025-07-06T08:55:51.22162Z",
          "iopub.status.idle": "2025-07-06T08:55:51.377235Z",
          "shell.execute_reply": "2025-07-06T08:55:51.376301Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.221947Z"
        },
        "id": "7Oe2ewC2pNO4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Store target and IDs\n",
        "y = np.log1p(train_df['SalePrice'])  # log-transform SalePrice\n",
        "test_ID = test_df['Id']\n",
        "\n",
        "# Drop Id and SalePrice\n",
        "X = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
        "X_test = test_df.drop(['Id'], axis=1)\n",
        "\n",
        "# Combine for preprocessing\n",
        "all_data = pd.concat([X, X_test], axis=0)\n",
        "\n",
        "# Fill missing values\n",
        "categorical_cols = all_data.select_dtypes(include='object').columns\n",
        "numerical_cols = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "all_data[categorical_cols] = all_data[categorical_cols].fillna(\"NA\")\n",
        "all_data[numerical_cols] = all_data[numerical_cols].apply(lambda col: col.fillna(col.median()))\n",
        "\n",
        "# One-hot encode\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "# Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "all_data_scaled = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns)\n",
        "\n",
        "# Split back to train and test\n",
        "X_all = all_data_scaled.iloc[:len(y), :]\n",
        "X_final_test = all_data_scaled.iloc[len(y):, :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.378484Z",
          "iopub.status.busy": "2025-07-06T08:55:51.378217Z",
          "iopub.status.idle": "2025-07-06T08:55:51.439422Z",
          "shell.execute_reply": "2025-07-06T08:55:51.438616Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.378463Z"
        },
        "id": "QyvFoOszpNO5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ==== STEP 4: One-Hot Encoding ====\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "# ==== STEP 5: Feature Scaling ====\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "all_data_scaled = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns)\n",
        "\n",
        "# ==== STEP 6: Re-split into train and test ====\n",
        "X_all = all_data_scaled.iloc[:len(y), :]\n",
        "X_final_test = all_data_scaled.iloc[len(y):, :]\n",
        "\n",
        "# ==== STEP 7: Train/Validation Split ====\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ==== STEP 8: Model Evaluation Function ====\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "def model_evaluation(y_test, y_pred, tolerance=0.1):\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    within_tolerance = np.abs(y_test - y_pred) <= (tolerance * y_test)\n",
        "    accuracy = np.mean(within_tolerance) * 100\n",
        "\n",
        "    print(\"\\n📊 Model Evaluation Summary\")\n",
        "    print(\"--------------------------------------\")\n",
        "    print(f\" R² Score       : {r2:.4f}\")\n",
        "    print(f\" MSE            : {mse:.4f}\")\n",
        "    print(f\" MAE            : {mae:.4f}\")\n",
        "    print(f\" RMSE           : {rmse:.4f}\")\n",
        "    print(f\" Accuracy (±{int(tolerance * 100)}%) : {accuracy:.2f}%\")\n",
        "    print(\"--------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.441329Z",
          "iopub.status.busy": "2025-07-06T08:55:51.440414Z",
          "iopub.status.idle": "2025-07-06T08:55:51.522413Z",
          "shell.execute_reply": "2025-07-06T08:55:51.520536Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.441294Z"
        },
        "id": "H83nOGdbpNO6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# No tuning, just 1st-degree poly features\n",
        "best_linear_model = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
        "    ('linreg', LinearRegression(fit_intercept=True))\n",
        "])\n",
        "\n",
        "best_linear_model.fit(X_train, y_train)\n",
        "y_pred_valid = best_linear_model.predict(X_valid)\n",
        "\n",
        "# Evaluation\n",
        "model_evaluation(y_valid, y_pred_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:51.523434Z",
          "iopub.status.busy": "2025-07-06T08:55:51.523157Z",
          "iopub.status.idle": "2025-07-06T08:55:52.355681Z",
          "shell.execute_reply": "2025-07-06T08:55:52.354703Z",
          "shell.execute_reply.started": "2025-07-06T08:55:51.52341Z"
        },
        "id": "rVscYW7JpNO6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "# Lighter set of base learners\n",
        "estimators = [\n",
        "    ('ridge', Ridge(alpha=10)),\n",
        "    ('lasso', Lasso(alpha=0.001, max_iter=10000)),\n",
        "    ('linear', best_linear_model)\n",
        "]\n",
        "\n",
        "stack = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=Ridge(alpha=5),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "y_pred_valid_stack = stack.predict(X_valid)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n Stacking Regressor Performance:\")\n",
        "model_evaluation(y_valid, y_pred_valid_stack)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4YErxyspNO7"
      },
      "source": [
        "### Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T08:55:52.356942Z",
          "iopub.status.busy": "2025-07-06T08:55:52.356623Z",
          "iopub.status.idle": "2025-07-06T08:55:52.391753Z",
          "shell.execute_reply": "2025-07-06T08:55:52.390454Z",
          "shell.execute_reply.started": "2025-07-06T08:55:52.356919Z"
        },
        "id": "zBQheSvJpNO8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Predict on the final test set\n",
        "y_pred_test = stack.predict(X_final_test)\n",
        "\n",
        "# Convert from log scale back to actual prices\n",
        "y_pred_test = np.expm1(y_pred_test)\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({'Id': test_ID, 'SalePrice': y_pred_test})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\" Submission file saved as 'submission.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvMw7b2ypNO8",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Celebal Assignment 5 - Regression",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 868283,
          "sourceId": 5407,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
